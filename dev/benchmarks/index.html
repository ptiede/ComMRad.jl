<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Benchmarks · Comrade.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Comrade.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Benchmarks</a><ul class="internal"><li><a class="tocitem" href="#Benchmarking-Problem"><span>Benchmarking Problem</span></a></li><li><a class="tocitem" href="#Results"><span>Results</span></a></li><li><a class="tocitem" href="#Code"><span>Code</span></a></li></ul></li><li><a class="tocitem" href="../vlbi_imaging_problem/">Introduction to the VLBI Imaging Problem</a></li><li><a class="tocitem" href="../conventions/">Conventions</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../examples/data/">Loading Data into Comrade</a></li><li><a class="tocitem" href="../examples/nonanalytic/">Modeling with non-analytic Fourier transforms</a></li><li><a class="tocitem" href="../examples/geometric_modeling/">Geometric Modeling of EHT Data</a></li><li><a class="tocitem" href="../examples/imaging_closures/">Imaging a Black Hole using only Closure Quantities</a></li><li><a class="tocitem" href="../examples/imaging_vis/">Stokes I Simultaneous Image and Instrument Modeling</a></li><li><a class="tocitem" href="../examples/imaging_pol/">Polarized Image and Instrumental Modeling</a></li><li><a class="tocitem" href="../examples/hybrid_imaging/">Hybrid Imaging of a Black Hole</a></li></ul></li><li><span class="tocitem">Libraries</span><ul><li><a class="tocitem" href="../libs/optimization/">ComradeOptimization</a></li><li><a class="tocitem" href="../libs/ahmc/">ComradeAHMC</a></li><li><a class="tocitem" href="../libs/nested/">ComradeNested</a></li><li><a class="tocitem" href="../libs/dynesty/">ComradeDynesty</a></li><li><a class="tocitem" href="../libs/adaptmcmc/">ComradeAdaptMCMC</a></li></ul></li><li><a class="tocitem" href="../interface/">Model Interface</a></li><li><a class="tocitem" href="../base_api/">ComradeBase API</a></li><li><a class="tocitem" href="../api/">Comrade API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Benchmarks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Benchmarks</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ptiede/Comrade.jl/blob/main/docs/src/benchmarks.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Benchmarks"><a class="docs-heading-anchor" href="#Benchmarks">Benchmarks</a><a id="Benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarks" title="Permalink"></a></h1><p><code>Comrade</code> was partially designed with performance in mind. Solving imaging inverse problems is traditionally very computationally expensive, especially since Comrade uses Bayesian inference. To benchmark <code>Comrade</code> we will compare it to two of the most common modeling or imaging packages within the EHT:</p><ul><li><a href="https://github.com/achael/eht-imaging/">eht-imaging</a></li><li><a href="https://iopscience.iop.org/article/10.3847/1538-4357/ab91a4">Themis</a></li></ul><p><code>eht-imaging</code><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> or <code>ehtim</code> is a Python package that is widely used within the EHT for its imaging and modeling interfaces. It is easy to use and is commonly used in the EHT. However, to specify the model, the user must specify how to calculate the model&#39;s complex visibilities <strong>and</strong> its gradients, allowing eht-imaging&#39;s modeling package to achieve acceptable speeds.</p><p>Themis is a C++ package focused on providing Bayesian estimates of the image structure. In fact, <code>Comrade</code> took some design cues from <code>Themis</code>. Themis has been used in various EHT publications and is the standard Bayesian modeling tool used in the EHT. However, <code>Themis</code> is quite challenging to use and requires a high level of knowledge from its users, requiring them to understand makefile, C++, and the MPI standard. Additionally, Themis provides no infrastructure to compute gradients, instead relying on finite differencing, which scales poorly for large numbers of model parameters. </p><h2 id="Benchmarking-Problem"><a class="docs-heading-anchor" href="#Benchmarking-Problem">Benchmarking Problem</a><a id="Benchmarking-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmarking-Problem" title="Permalink"></a></h2><p>For our benchmarking problem, we analyze a situation very similar to the one explained in <a href="../examples/geometric_modeling/#Geometric-Modeling-of-EHT-Data">Geometric Modeling of EHT Data</a>. Namely, we will consider fitting 2017 M87 April 6 data using an m-ring and a single Gaussian component. Please see the end of this page to see the code we used for <code>Comrade</code> and <code>eht-imaging</code>.</p><h2 id="Results"><a class="docs-heading-anchor" href="#Results">Results</a><a id="Results-1"></a><a class="docs-heading-anchor-permalink" href="#Results" title="Permalink"></a></h2><p>All tests were run using the following system</p><pre><code class="language-julia hljs">Julia Version 1.7.3
Python Version 3.10.5
Comrade Version 0.4.0
eht-imaging Version 1.2.4
Commit 742b9abb4d (2022-05-06 12:58 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: 11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-12.0.1 (ORCJIT, tigerlake)</code></pre><p>Our benchmark results are the following:</p><table><tr><th style="text-align: right"></th><th style="text-align: right">Comrade (micro sec)</th><th style="text-align: right">eht-imaging (micro sec)</th><th style="text-align: right">Themis (micro sec)</th></tr><tr><td style="text-align: right">posterior eval (min)</td><td style="text-align: right">31</td><td style="text-align: right">445</td><td style="text-align: right">55</td></tr><tr><td style="text-align: right">posterior eval (mean)</td><td style="text-align: right">36</td><td style="text-align: right">476</td><td style="text-align: right">60</td></tr><tr><td style="text-align: right">grad posterior eval (min)</td><td style="text-align: right">105 (ForwardDiff)</td><td style="text-align: right">1898</td><td style="text-align: right">1809</td></tr><tr><td style="text-align: right">grad posterior eval (mean)</td><td style="text-align: right">119 (ForwardDiff)</td><td style="text-align: right">1971</td><td style="text-align: right">1866</td></tr></table><p>Therefore, for this test we found that <code>Comrade</code> was the fastest method in all tests. For the posterior evaluation we found that Comrade is &gt; 10x faster than <code>eht-imaging</code>, and 2x faster then <code>Themis</code>. For gradient evaluations we have <code>Comrade</code> is &gt; 15x faster than both <code>eht-imaging</code> and <code>Themis</code>.</p><h2 id="Code"><a class="docs-heading-anchor" href="#Code">Code</a><a id="Code-1"></a><a class="docs-heading-anchor-permalink" href="#Code" title="Permalink"></a></h2><h3 id="Julia-Code"><a class="docs-heading-anchor" href="#Julia-Code">Julia Code</a><a id="Julia-Code-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-Code" title="Permalink"></a></h3><pre><code class="language-julia hljs">using Pyehtim
using Comrade
using Distributions
using BenchmarkTools
using ForwardDiff

# To download the data visit https://doi.org/10.25739/g85n-f134
obs = ehtim.obsdata.load_uvfits((joinpath(@__DIR__, &quot;assets/SR1_M87_2017_096_lo_hops_netcal_StokesI.uvfits&quot;))
obs = scan_average(obs)
amp = extract_amp(obs)

function model(θ)
    (;rad, wid, a, b, f, sig, asy, pa, x, y) = θ
    ring = f*smoothed(stretched(MRing((a,), (b,)), μas2rad(rad), μas2rad(rad)), μas2rad(wid))
    g = (1-f)*shifted(rotated(stretched(Gaussian(), μas2rad(sig)*asy, μas2rad(sig)), pa), μas2rad(x), μas2rad(y))
    return ring + g
end

lklhd = RadioLikelihood(model, amp)
prior = (
          rad = Uniform(10.0, 30.0),
          wid = Uniform(1.0, 10.0),
          a = Uniform(-0.5, 0.5), b = Uniform(-0.5, 0.5),
          f = Uniform(0.0, 1.0),
          sig = Uniform((1.0), (60.0)),
          asy = Uniform(0.0, 0.9),
          pa = Uniform(0.0, 1π),
          x = Uniform(-(80.0), (80.0)),
          y = Uniform(-(80.0), (80.0))
        )

θ = (rad= 22.0, wid= 3.0, a = 0.0, b = 0.15, f=0.8, sig = 20.0, asy=0.2, pa=π/2, x=20.0, y=20.0)
m = model(θ)

post = Posterior(lklhd, prior)
tpost = asflat(post)

# Transform to the unconstrained space
x0 = inverse(tpost, θ)

# Lets benchmark the posterior evaluation
ℓ = logdensityof(tpost)
@benchmark ℓ($x0)

using LogDensityProblemsAD
# Now we benchmark the gradient
gℓ = ADgradient(Val(:ForwardDiff), tpost)
@benchmark LogDensityProblemsAD.logdensity_and_gradient($gℓ, $x0)</code></pre><h3 id="eht-imaging-Code"><a class="docs-heading-anchor" href="#eht-imaging-Code">eht-imaging Code</a><a id="eht-imaging-Code-1"></a><a class="docs-heading-anchor-permalink" href="#eht-imaging-Code" title="Permalink"></a></h3><pre><code class="language-julia hljs"># To download the data visit https://doi.org/10.25739/g85n-f134
obs = ehtim.obsdata.load_uvfits((joinpath(@__DIR__, &quot;assets/SR1_M87_2017_096_lo_hops_netcal_StokesI.uvfits&quot;))
obs = scan_average(obs)



meh = ehtim.model.Model()
meh = meh.add_thick_mring(F0=θ.f,
                    d=2*μas2rad(θ.rad),
                    alpha=2*sqrt(2*log(2))*μas2rad(θ.wid),
                    x0 = 0.0,
                    y0 = 0.0,
                    beta_list=[0.0+θ.b]
                    )
meh = meh.add_gauss(F0=1-θ.f,
                    FWHM_maj=2*sqrt(2*log(2))*μas2rad(θ.sig),
                    FWHM_min=2*sqrt(2*log(2))*μas2rad(θ.sig)*θ.asy,
                    PA = θ.pa,
                    x0 = μas2rad(20.0),
                    y0 = μas2rad(20.0)
                    )

preh = meh.default_prior()
preh[1][&quot;F0&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;0.0, &quot;max&quot;=&gt;1.0)
preh[1][&quot;d&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;μas2rad(20.0), &quot;max&quot;=&gt;μas2rad(60.0))
preh[1][&quot;alpha&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;μas2rad(2.0), &quot;max&quot;=&gt;μas2rad(25.0))
preh[1][&quot;x0&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;fixed&quot;)
preh[1][&quot;y0&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;fixed&quot;)

preh[2][&quot;F0&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;0.0, &quot;max&quot;=&gt;1.0)
preh[2][&quot;FWHM_maj&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;μas2rad(2.0), &quot;max&quot;=&gt;μas2rad(120.0))
preh[2][&quot;FWHM_min&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;μas2rad(2.0), &quot;max&quot;=&gt;μas2rad(120.0))
preh[2][&quot;x0&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;-μas2rad(40.0), &quot;max&quot;=&gt;μas2rad(40.0))
preh[2][&quot;y0&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;-μas2rad(40.0), &quot;max&quot;=&gt;μas2rad(40.0))
preh[2][&quot;PA&quot;] = Dict(&quot;prior_type&quot;=&gt;&quot;flat&quot;, &quot;min&quot;=&gt;-1π, &quot;max&quot;=&gt;1π)

using PyCall
py&quot;&quot;&quot;
import ehtim
import numpy as np
transform_param = ehtim.modeling.modeling_utils.transform_param
def make_paraminit(param_map, meh, trial_model, model_prior):
    model_init = meh.copy()
    param_init = []
    for j in range(len(param_map)):
        pm = param_map[j]
        if param_map[j][1] in trial_model.params[param_map[j][0]].keys():
            param_init.append(transform_param(model_init.params[pm[0]][pm[1]]/pm[2], model_prior[pm[0]][pm[1]],inverse=False))
        else: # In this case, the parameter is a list of complex numbers, so the real/imaginary or abs/arg components need to be assigned
            if param_map[j][1].find(&#39;cpol&#39;) != -1:
                param_type = &#39;beta_list_cpol&#39;
                idx = int(param_map[j][1].split(&#39;_&#39;)[0][8:])
            elif param_map[j][1].find(&#39;pol&#39;) != -1:
                param_type = &#39;beta_list_pol&#39;
                idx = int(param_map[j][1].split(&#39;_&#39;)[0][7:]) + (len(trial_model.params[param_map[j][0]][param_type])-1)//2
            elif param_map[j][1].find(&#39;beta&#39;) != -1:
                param_type = &#39;beta_list&#39;
                idx = int(param_map[j][1].split(&#39;_&#39;)[0][4:]) - 1
            else:
                raise Exception(&#39;Unsure how to interpret &#39; + param_map[j][1])

            curval = model_init.params[param_map[j][0]][param_type][idx]
            if &#39;_&#39; not in param_map[j][1]:
                param_init.append(transform_param(np.real( model_init.params[pm[0]][param_type][idx]/pm[2]), model_prior[pm[0]][pm[1]],inverse=False))
            elif   param_map[j][1][-2:] == &#39;re&#39;:
                param_init.append(transform_param(np.real( model_init.params[pm[0]][param_type][idx]/pm[2]), model_prior[pm[0]][pm[1]],inverse=False))
            elif param_map[j][1][-2:] == &#39;im&#39;:
                param_init.append(transform_param(np.imag( model_init.params[pm[0]][param_type][idx]/pm[2]), model_prior[pm[0]][pm[1]],inverse=False))
            elif param_map[j][1][-3:] == &#39;abs&#39;:
                param_init.append(transform_param(np.abs(  model_init.params[pm[0]][param_type][idx]/pm[2]), model_prior[pm[0]][pm[1]],inverse=False))
            elif param_map[j][1][-3:] == &#39;arg&#39;:
                param_init.append(transform_param(np.angle(model_init.params[pm[0]][param_type][idx])/pm[2], model_prior[pm[0]][pm[1]],inverse=False))
            else:
                if not quiet: print(&#39;Parameter &#39; + param_map[j][1] + &#39; not understood!&#39;)
    n_params = len(param_init)
    return n_params, param_init
&quot;&quot;&quot;

# make the python param map and use optimize so we flatten the parameter space.
pmap, pmask = ehtim.modeling.modeling_utils.make_param_map(meh, preh, &quot;scipy.optimize.dual_annealing&quot;, fit_model=true)
trial_model = meh.copy()

# get initial parameters
n_params, pinit = py&quot;make_paraminit&quot;(pmap, meh, trial_model, preh)

# make data products for the globdict
data1, sigma1, uv1, _ = ehtim.modeling.modeling_utils.chisqdata(obs, &quot;amp&quot;)
data2, sigma2, uv2, _ = ehtim.modeling.modeling_utils.chisqdata(obs, false)
data3, sigma3, uv3, _ = ehtim.modeling.modeling_utils.chisqdata(obs, false)

# now set the ehtim modeling globdict

ehtim.modeling.modeling_utils.globdict = Dict(&quot;trial_model&quot;=&gt;trial_model,
                &quot;d1&quot;=&gt;&quot;amp&quot;, &quot;d2&quot;=&gt;false, &quot;d3&quot;=&gt;false,
                &quot;pol1&quot;=&gt;&quot;I&quot;, &quot;pol2&quot;=&gt;&quot;I&quot;, &quot;pol3&quot;=&gt;&quot;I&quot;,
                &quot;data1&quot;=&gt;data1, &quot;sigma1&quot;=&gt;sigma1, &quot;uv1&quot;=&gt;uv1, &quot;jonesdict1&quot;=&gt;nothing,
                &quot;data2&quot;=&gt;data2, &quot;sigma2&quot;=&gt;sigma2, &quot;uv2&quot;=&gt;uv2, &quot;jonesdict2&quot;=&gt;nothing,
                &quot;data3&quot;=&gt;data3, &quot;sigma3&quot;=&gt;sigma3, &quot;uv3&quot;=&gt;uv3, &quot;jonesdict3&quot;=&gt;nothing,
                &quot;alpha_d1&quot;=&gt;0, &quot;alpha_d2&quot;=&gt;0, &quot;alpha_d3&quot;=&gt;0,
                &quot;n_params&quot;=&gt; n_params, &quot;n_gains&quot;=&gt;0, &quot;n_leakage&quot;=&gt;0,
                &quot;model_prior&quot;=&gt;preh, &quot;param_map&quot;=&gt;pmap, &quot;param_mask&quot;=&gt;pmask,
                &quot;gain_prior&quot;=&gt;nothing, &quot;gain_list&quot;=&gt;[], &quot;gain_init&quot;=&gt;nothing,
                &quot;fit_leakage&quot;=&gt;false, &quot;leakage_init&quot;=&gt;[], &quot;leakage_fit&quot;=&gt;[],
                &quot;station_leakages&quot;=&gt;nothing, &quot;leakage_prior&quot;=&gt;nothing,
                &quot;show_updates&quot;=&gt;false, &quot;update_interval&quot;=&gt;1,
                &quot;gains_t1&quot;=&gt;nothing, &quot;gains_t2&quot;=&gt;nothing,
                &quot;minimizer_func&quot;=&gt;&quot;scipy.optimize.dual_annealing&quot;,
                &quot;Obsdata&quot;=&gt;obs,
                &quot;fit_pol&quot;=&gt;false, &quot;fit_cpol&quot;=&gt;false,
                &quot;flux&quot;=&gt;1.0, &quot;alpha_flux&quot;=&gt;0, &quot;fit_gains&quot;=&gt;false,
                &quot;marginalize_gains&quot;=&gt;false, &quot;ln_norm&quot;=&gt;1314.33,
                &quot;param_init&quot;=&gt;pinit, &quot;test_gradient&quot;=&gt;false
            )

# This is the negative log-posterior
fobj = ehtim.modeling.modeling_utils.objfunc

# This is the gradient of the negative log-posterior
gfobj = ehtim.modeling.modeling_utils.objgrad

# Lets benchmark the posterior evaluation
@benchmark fobj($pinit)

# Now we benchmark the gradient
@benchmark gfobj($pinit)</code></pre><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Chael A, et al. <em>Inteferometric Imaging Directly with Closure Phases</em> 2018 ApJ 857 1 arXiv:1803/07088</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../vlbi_imaging_problem/">Introduction to the VLBI Imaging Problem »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Friday 2 June 2023 02:43">Friday 2 June 2023</span>. Using Julia version 1.9.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
