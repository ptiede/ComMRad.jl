<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Hybrid Imaging of a Black Hole · Comrade.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Comrade.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../benchmarks/">Benchmarks</a></li><li><a class="tocitem" href="../../vlbi_imaging_problem/">Introduction to the VLBI Imaging Problem</a></li><li><a class="tocitem" href="../../conventions/">Conventions</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../data/">Loading Data into Comrade</a></li><li><a class="tocitem" href="../nonanalytic/">Modeling with non-analytic Fourier transforms</a></li><li><a class="tocitem" href="../geometric_modeling/">Geometric Modeling of EHT Data</a></li><li><a class="tocitem" href="../imaging_closures/">Imaging a Black Hole using only Closure Quantities</a></li><li><a class="tocitem" href="../imaging_vis/">Stokes I Simultaneous Image and Instrument Modeling</a></li><li><a class="tocitem" href="../imaging_pol/">Polarized Image and Instrumental Modeling</a></li><li class="is-active"><a class="tocitem" href>Hybrid Imaging of a Black Hole</a><ul class="internal"><li><a class="tocitem" href="#Introduction-to-Hybrid-modeling-and-imaging"><span>Introduction to Hybrid modeling and imaging</span></a></li><li><a class="tocitem" href="#Loading-the-Data"><span>Loading the Data</span></a></li><li><a class="tocitem" href="#Load-the-Data"><span>Load the Data</span></a></li><li><a class="tocitem" href="#Building-the-Model/Posterior"><span>Building the Model/Posterior</span></a></li><li><a class="tocitem" href="#Reconstructing-the-Image"><span>Reconstructing the Image</span></a></li><li><a class="tocitem" href="#Computing-information"><span>Computing information</span></a></li></ul></li></ul></li><li><span class="tocitem">Libraries</span><ul><li><a class="tocitem" href="../../libs/optimization/">ComradeOptimization</a></li><li><a class="tocitem" href="../../libs/ahmc/">ComradeAHMC</a></li><li><a class="tocitem" href="../../libs/nested/">ComradeNested</a></li><li><a class="tocitem" href="../../libs/dynesty/">ComradeDynesty</a></li><li><a class="tocitem" href="../../libs/adaptmcmc/">ComradeAdaptMCMC</a></li></ul></li><li><a class="tocitem" href="../../interface/">Model Interface</a></li><li><a class="tocitem" href="../../base_api/">ComradeBase API</a></li><li><a class="tocitem" href="../../api/">Comrade API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Hybrid Imaging of a Black Hole</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Hybrid Imaging of a Black Hole</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ptiede/Comrade.jl/blob/main/examples/hybrid_imaging.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Hybrid-Imaging-of-a-Black-Hole"><a class="docs-heading-anchor" href="#Hybrid-Imaging-of-a-Black-Hole">Hybrid Imaging of a Black Hole</a><a id="Hybrid-Imaging-of-a-Black-Hole-1"></a><a class="docs-heading-anchor-permalink" href="#Hybrid-Imaging-of-a-Black-Hole" title="Permalink"></a></h1><p>In this tutorial, we will use <strong>hybrid imaging</strong> to analyze the 2017 EHT data. By hybrid imaging, we mean decomposing the model into simple geometric models, e.g., rings and such, plus a rasterized image model to soak up the additional structure. This approach was first developed in <a href="https://iopscience.iop.org/article/10.3847/1538-4357/ab9c1f"><code>BB20</code></a> and applied to EHT 2017 data. We will use a similar model in this tutorial.</p><h2 id="Introduction-to-Hybrid-modeling-and-imaging"><a class="docs-heading-anchor" href="#Introduction-to-Hybrid-modeling-and-imaging">Introduction to Hybrid modeling and imaging</a><a id="Introduction-to-Hybrid-modeling-and-imaging-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction-to-Hybrid-modeling-and-imaging" title="Permalink"></a></h2><p>The benefit of using a hybrid-based modeling approach is the effective compression of information/parameters when fitting the data. Hybrid modeling requires the user to incorporate specific knowledge of how you expect the source to look like. For instance for M87, we expect the image to be dominated by a ring-like structure. Therefore, instead of using a high-dimensional raster to recover the ring, we can use a ring model plus a very low-dimensional or large pixel size raster to soak up the rest of the emission. This is the approach we will take in this tutorial to analyze the April 6 2017 EHT data of M87.</p><h2 id="Loading-the-Data"><a class="docs-heading-anchor" href="#Loading-the-Data">Loading the Data</a><a id="Loading-the-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-the-Data" title="Permalink"></a></h2><p>To get started we will load Comrade</p><pre><code class="language- hljs">using Comrade</code></pre><h2 id="Load-the-Data"><a class="docs-heading-anchor" href="#Load-the-Data">Load the Data</a><a id="Load-the-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Load-the-Data" title="Permalink"></a></h2><pre><code class="language- hljs">using Pkg #hide
Pkg.activate(joinpath(dirname(pathof(Comrade)), &quot;..&quot;, &quot;examples&quot;)) #hide

using Pyehtim</code></pre><p>For reproducibility we use a stable random number genreator</p><pre><code class="language- hljs">using StableRNGs
rng = StableRNG(42)</code></pre><p>To download the data visit https://doi.org/10.25739/g85n-f134 To load the eht-imaging obsdata object we do:</p><pre><code class="language- hljs">obs = ehtim.obsdata.load_uvfits(joinpath(dirname(pathof(Comrade)), &quot;..&quot;, &quot;examples&quot;, &quot;SR1_M87_2017_096_lo_hops_netcal_StokesI.uvfits&quot;))</code></pre><p>Now we do some minor preprocessing:</p><ul><li>Scan average the data since the data have been preprocessed so that the gain phases  coherent.</li></ul><pre><code class="language- hljs">obs = scan_average(obs).add_fractional_noise(0.02)</code></pre><p>For this tutorial we will stick to fitting closure only data, although we can get better results by also modeling gains, since closure only modeling is equivalent to assuming infinite gain priors.</p><pre><code class="language- hljs">dlcamp, dcphase  = extract_table(obs, LogClosureAmplitudes(;snrcut=3), ClosurePhases(;snrcut=3))</code></pre><h2 id="Building-the-Model/Posterior"><a class="docs-heading-anchor" href="#Building-the-Model/Posterior">Building the Model/Posterior</a><a id="Building-the-Model/Posterior-1"></a><a class="docs-heading-anchor-permalink" href="#Building-the-Model/Posterior" title="Permalink"></a></h2><p>Now we build our intensity/visibility model. That is, the model that takes in a named tuple of parameters and perhaps some metadata required to construct the model. For our model, we will use a raster or <code>ContinuousImage</code> model, an <code>m-ring</code> model, and a large asymmetric Gaussian component to model the unresolved short-baseline flux.</p><pre><code class="language-julia hljs">function model(θ, metadata)
    (;c, f, r, σ, ma, mp, fg, σg, τg, ξg) = θ
    (; grid, cache) = metadata
    # Form the image model
    img = IntensityMap(f*(1-fg)*c, grid)
    mimg = ContinuousImage(img, cache)
    # Form the ring model
    s,c = sincos(mp)
    α = ma*c
    β = ma*s
    ring = ((1-f)*(1-fg))*smoothed(stretched(MRing(α, β), r, r),σ)
    gauss = fg*rotated(stretched(Gaussian(), σg, σg*(1+τg)), ξg)
    return mimg + (ring + gauss)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">model (generic function with 1 method)</code></pre><p>Before we move on, let&#39;s go into the <code>model</code> function a bit. This function takes two arguments <code>θ</code> and <code>metadata</code>. The <code>θ</code> argument is a named tuple of parameters that are fit to the data. The <code>metadata</code> argument is all the ancillary information we need to construct the model. For our hybrid model, we will need two variables for the metadata, a <code>grid</code> that specifies the locations of the image pixels and a <code>cache</code> that defines the algorithm used to calculate the visibilities given the image model. This is required since <code>ContinuousImage</code> is most easily computed using number Fourier transforms like the <a href="https://github.com/JuliaMath/NFFT.jl"><code>NFFT</code></a> or <a href="https://github.com/JuliaMath/FFTW.jl">FFT</a>. To combine the models, we use <code>Comrade</code>&#39;s overloaded <code>+</code> operators, which will combine the images such that their intensities and visibilities are added pointwise.</p><p>Now let&#39;s define our metadata. First we will define the cache for the image. This is required to compute the numerical Fourier transform.</p><pre><code class="language- hljs">fovxy  = μas2rad(90.0)
npix   = 6
grid   = imagepixels(fovxy, fovxy, npix, npix)
buffer = IntensityMap(zeros(npix,npix), grid)</code></pre><p>For our image, we will use the discrete Fourier transform (<code>DFTAlg</code>) since we use such a small dimensional image. For larger rasters (8x8 and above) we recommend using <code>NFFTAlg</code> instead of <code>DFFTAlg</code> due to the improved scaling. The last argument to the <code>create_cache</code> call is the image <em>kernel</em> or <em>pulse</em> defines the continuous function we convolve our image with to produce a continuous on-sky image.</p><pre><code class="language- hljs">cache  = create_cache(DFTAlg(dlcamp), buffer, BSplinePulse{3}())</code></pre><p>Now we form the metadata</p><pre><code class="language- hljs">metadata = (;grid, cache)</code></pre><p>This is everything we need to form our likelihood. Note the first two arguments must be the model and then the metadata for the likelihood. The rest of the arguments are required to be <a href="../../api/#Comrade.EHTObservation"><code>Comrade.EHTObservation</code></a></p><pre><code class="language- hljs">lklhd = RadioLikelihood(model, dlcamp, dcphase;
                        skymeta=metadata)</code></pre><p>This forms our model. The next step is defining our image priors. For our raster <code>c</code>, we will use a <em>Dirichlet</em> prior, a multivariate prior that exists on the simplex. That is, the sum of all the numbers from a <code>Dirichlet</code> distribution always equals unity. The first parameter is the concentration parameter <code>α</code>. As <code>α→0</code>, the images tend to become very sparse, while for <code>α &gt;&gt; 1</code>, the images tend to have uniform brightness. The <code>α=1</code> distribution is the uniform distribution on the simplex. For our work here, we use the uniform simplex distribution.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>As α gets small sampling, it gets very difficult and quite multimodal due to the nature of the sparsity prior, be careful when checking convergence when using such a prior.</p></div></div><pre><code class="language- hljs">using VLBIImagePriors
using Distributions
prior = (
          c  = ImageDirichlet(1.0, npix, npix),
          f  = Uniform(0.0, 1.0),
          r  = Uniform(μas2rad(10.0), μas2rad(30.0)),
          σ  = Uniform(μas2rad(0.5), μas2rad(20.0)),
          ma = Uniform(0.0, 0.5),
          mp = Uniform(0.0, 2π),
          fg = Uniform(0.2, 1.0),
          σg = Uniform(μas2rad(50.0), μas2rad(500.0)),
          τg = Uniform(0.0, 1.0),
          ξg = Uniform(0, π)
        )</code></pre><p>This is everything we need to specify our posterior distribution, which our is the main object of interest in image reconstructions when using Bayesian inference.</p><pre><code class="language- hljs">post = Posterior(lklhd, prior)</code></pre><p>To sample from our prior we can do</p><pre><code class="language- hljs">xrand = prior_sample(rng, post)</code></pre><p>and then plot the results</p><pre><code class="language- hljs">using Plots
img = intensitymap(skymodel(post, xrand), μas2rad(120.0), μas2rad(120.0), 128, 128)
plot(img, title=&quot;Random sample&quot;)</code></pre><h2 id="Reconstructing-the-Image"><a class="docs-heading-anchor" href="#Reconstructing-the-Image">Reconstructing the Image</a><a id="Reconstructing-the-Image-1"></a><a class="docs-heading-anchor-permalink" href="#Reconstructing-the-Image" title="Permalink"></a></h2><p>To sample from this posterior, it is convenient to first move from our constrained parameter space to an unconstrained one (i.e., the support of the transformed posterior is (-∞, ∞)). This is done using the <code>asflat</code> function.</p><pre><code class="language- hljs">tpost = asflat(post)</code></pre><p>We can now also find the dimension of our posterior or the number of parameters we will sample.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This can often be different from what you would expect. This is especially true when using angular variables, where we often artificially increase the dimension of the parameter space to make sampling easier.</p></div></div><pre><code class="language- hljs">ndim = dimension(tpost)</code></pre><p>Now we optimize. First, we will use BlackBoxOptim, which is a genetic algorithm, to get us in the region of the best-fit model.</p><pre><code class="language- hljs">using ComradeOptimization
using OptimizationBBO
using Zygote
f = OptimizationFunction(tpost, Optimization.AutoZygote())
prob = Optimization.OptimizationProblem(f, prior_sample(rng, tpost), nothing, lb=fill(-5.0, ndim), ub=fill(5.0,ndim))
sol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited(); maxiters=100_000);
nothing #hide</code></pre><p>Alright now we can zoom to the peak!</p><pre><code class="language- hljs">using OptimizationOptimJL
prob = Optimization.OptimizationProblem(f, sol.u, nothing)
ℓ = logdensityof(tpost)
sol = solve(prob, LBFGS(), maxiters=1_000, g_tol=1e-1)</code></pre><p>Before we analyze our solution we first need to transform back to parameter space.</p><pre><code class="language- hljs">xopt = transform(tpost, sol)</code></pre><p>First we will evaluate our fit by plotting the residuals</p><pre><code class="language- hljs">residual(skymodel(post, xopt), dlcamp)
residual(skymodel(post, xopt), dcphase)</code></pre><p>These look reasonable, although they are a bit high. This could be improved in a few ways, but that is beyond the goal of this quick tutorial. Plotting the image, we see that we have a ring and an image that looks like a sharper version of the original M87 image. This is because we used a more physically motivated model by assuming that the image should have a ring component.</p><pre><code class="language- hljs">img = intensitymap(model(xopt, metadata), 1.5*fovxy, 1.5*fovxy, 128, 128)
plot(img, title=&quot;MAP Image&quot;)</code></pre><p>now we sample using hmc</p><pre><code class="language- hljs">using ComradeAHMC
metric = DiagEuclideanMetric(ndim)
chain, stats = sample(rng, post, AHMC(;metric, autodiff=Val(:Zygote)), 500; nadapts=250, init_params=xopt)</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This should be run for likely an order of magnitude more steps to properly estimate expectations of the posterior</p></div></div><p>Now lets plot the mean image and standard deviation images. To do this we first clip the first 250 MCMC steps since that is during tuning and so the posterior is not sampling from the correct stationary distribution.</p><pre><code class="language- hljs">using StatsBase
msamples = skymodel.(Ref(post), chain[251:2:end]);
nothing #hide</code></pre><p>The mean image is then given by</p><pre><code class="language- hljs">imgs = intensitymap.(msamples, 1.5*fovxy, 1.5*fovxy, 128, 128)
plot(mean(imgs), title=&quot;Mean Image&quot;)
plot(std(imgs), title=&quot;Std Dev.&quot;)</code></pre><p>We can also split up the model into its components and analyze each separately</p><pre><code class="language- hljs">comp = Comrade.components.(msamples)
ring_samples = getindex.(comp, 2)
rast_samples = first.(comp)
ring_imgs = intensitymap.(ring_samples, fovxy, fovxy, 128, 128)
rast_imgs = intensitymap.(rast_samples, fovxy, fovxy, 128, 128)

ring_mean, ring_std = mean_and_std(ring_imgs)
rast_mean, rast_std = mean_and_std(rast_imgs)

p1 = plot(ring_mean, title=&quot;Ring Mean&quot;, clims=(0.0, maximum(ring_mean)), colorbar=:none)
p2 = plot(ring_std, title=&quot;Ring Std. Dev.&quot;, clims=(0.0, maximum(ring_mean)), colorbar=:none)
p3 = plot(rast_mean, title=&quot;Raster Mean&quot;, clims=(0.0, maximum(ring_mean)), colorbar=:none)
p4 = plot(rast_std,  title=&quot;Raster Std. Dev.&quot;, clims=(0.0, maximum(ring_mean)), colorbar=:none)

plot(p1,p2,p3,p4, layout=(2,2), size=(650, 650))</code></pre><p>Finally, let&#39;s take a look at some of the ring parameters</p><pre><code class="language- hljs">using StatsPlots
p1 = density(rad2μas(chain.r)*2, xlabel=&quot;Ring Diameter (μas)&quot;)
p2 = density(rad2μas(chain.σ)*2*sqrt(2*log(2)), xlabel=&quot;Ring FWHM (μas)&quot;)
p3 = density(-rad2deg.(chain.mp) .+ 360.0, xlabel = &quot;Ring PA (deg) E of N&quot;)
p4 = density(2*chain.ma, xlabel=&quot;Brightness asymmetry&quot;)
p5 = density(1 .- chain.f, xlabel=&quot;Ring flux fraction&quot;)
plot(p1, p2, p3, p4, p5, size=(900, 600), legend=nothing)</code></pre><p>This is very consistent with the original M87 results and it only took 20 minutes compared to the week it used to take using old imaging tools.</p><h2 id="Computing-information"><a class="docs-heading-anchor" href="#Computing-information">Computing information</a><a id="Computing-information-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-information" title="Permalink"></a></h2><pre><code class="nohighlight hljs">Julia Version 1.8.5
Commit 17cfb8e65ea (2023-01-08 06:45 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: 32 × AMD Ryzen 9 7950X 16-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-13.0.1 (ORCJIT, znver3)
  Threads: 1 on 32 virtual cores
Environment:
  JULIA_EDITOR = code
  JULIA_NUM_THREADS = 1</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../imaging_pol/">« Polarized Image and Instrumental Modeling</a><a class="docs-footer-nextpage" href="../../libs/optimization/">ComradeOptimization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 8 June 2023 12:56">Thursday 8 June 2023</span>. Using Julia version 1.9.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
