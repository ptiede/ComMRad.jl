<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Imaging a Black Hole using only Closure Quantities · Comrade.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Comrade.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../benchmarks/">Benchmarks</a></li><li><a class="tocitem" href="../../vlbi_imaging_problem/">Introduction to the VLBI Imaging Problem</a></li><li><a class="tocitem" href="../../conventions/">Conventions</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../data/">Loading Data into Comrade</a></li><li><a class="tocitem" href="../nonanalytic/">Modeling with non-analytic Fourier transforms</a></li><li><a class="tocitem" href="../geometric_modeling/">Geometric Modeling of EHT Data</a></li><li class="is-active"><a class="tocitem" href>Imaging a Black Hole using only Closure Quantities</a><ul class="internal"><li><a class="tocitem" href="#Introduction-to-Closure-Imaging"><span>Introduction to Closure Imaging</span></a></li><li><a class="tocitem" href="#Load-the-Data"><span>Load the Data</span></a></li><li><a class="tocitem" href="#Build-the-Model/Posterior"><span>Build the Model/Posterior</span></a></li><li><a class="tocitem" href="#Reconstructing-the-Image"><span>Reconstructing the Image</span></a></li><li><a class="tocitem" href="#Computing-information"><span>Computing information</span></a></li></ul></li><li><a class="tocitem" href="../imaging_vis/">Stokes I Simultaneous Image and Instrument Modeling</a></li><li><a class="tocitem" href="../imaging_pol/">Polarized Image and Instrumental Modeling</a></li><li><a class="tocitem" href="../hybrid_imaging/">Hybrid Imaging of a Black Hole</a></li></ul></li><li><span class="tocitem">Libraries</span><ul><li><a class="tocitem" href="../../libs/optimization/">ComradeOptimization</a></li><li><a class="tocitem" href="../../libs/ahmc/">ComradeAHMC</a></li><li><a class="tocitem" href="../../libs/nested/">ComradeNested</a></li><li><a class="tocitem" href="../../libs/dynesty/">ComradeDynesty</a></li><li><a class="tocitem" href="../../libs/adaptmcmc/">ComradeAdaptMCMC</a></li></ul></li><li><a class="tocitem" href="../../interface/">Model Interface</a></li><li><a class="tocitem" href="../../base_api/">ComradeBase API</a></li><li><a class="tocitem" href="../../api/">Comrade API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Imaging a Black Hole using only Closure Quantities</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Imaging a Black Hole using only Closure Quantities</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ptiede/Comrade.jl/blob/main/examples/imaging_closures.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Imaging-a-Black-Hole-using-only-Closure-Quantities"><a class="docs-heading-anchor" href="#Imaging-a-Black-Hole-using-only-Closure-Quantities">Imaging a Black Hole using only Closure Quantities</a><a id="Imaging-a-Black-Hole-using-only-Closure-Quantities-1"></a><a class="docs-heading-anchor-permalink" href="#Imaging-a-Black-Hole-using-only-Closure-Quantities" title="Permalink"></a></h1><p>In this tutorial, we will create a preliminary reconstruction of the 2017 M87 data on April 6 using closure-only imaging. This tutorial is a general introduction to closure-only imaging in Comrade. For an introduction to simultaneous image and instrument modeling, see <a href="../imaging_vis/#Stokes-I-Simultaneous-Image-and-Instrument-Modeling">Stokes I Simultaneous Image and Instrument Modeling</a></p><h2 id="Introduction-to-Closure-Imaging"><a class="docs-heading-anchor" href="#Introduction-to-Closure-Imaging">Introduction to Closure Imaging</a><a id="Introduction-to-Closure-Imaging-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction-to-Closure-Imaging" title="Permalink"></a></h2><p>The EHT is the highest-resolution telescope ever created. Its resolution is equivalent to roughly tracking a hockey puck on the moon when viewing it from the earth. However, the EHT is also a unique interferometer. For one, the data it produces is incredibly sparse. The array is formed from only eight geographic locations around the planet, each with its unique telescope. Additionally, the EHT observes at a much higher frequency than typical interferometers. As a result, it is often difficult to directly provide calibrated data since the source model can be complicated. This implies there can be large instrumental effects often called <em>gains</em> that can corrupt our signal. One way to deal with this is to fit quantities that are independent of gains. These are often called <strong>closure quantities</strong>. The types of closure quantities are briefly described in <a href="../../vlbi_imaging_problem/#Introduction-to-the-VLBI-Imaging-Problem">Introduction to the VLBI Imaging Problem</a>.</p><p>In this tutorial, we will do closure-only modeling of M87 to produce preliminary images of M87.</p><p>To get started, we will load Comrade</p><pre><code class="language- hljs">using Comrade


using Pkg #hide
Pkg.activate(joinpath(dirname(pathof(Comrade)), &quot;..&quot;, &quot;examples&quot;)) #hide

using Pyehtim</code></pre><p>For reproducibility we use a stable random number genreator</p><pre><code class="language- hljs">using StableRNGs
rng = StableRNG(123)</code></pre><h2 id="Load-the-Data"><a class="docs-heading-anchor" href="#Load-the-Data">Load the Data</a><a id="Load-the-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Load-the-Data" title="Permalink"></a></h2><p>To download the data visit https://doi.org/10.25739/g85n-f134 To load the eht-imaging obsdata object we do:</p><pre><code class="language- hljs">obs = ehtim.obsdata.load_uvfits(joinpath(dirname(pathof(Comrade)), &quot;..&quot;, &quot;examples&quot;, &quot;SR1_M87_2017_096_lo_hops_netcal_StokesI.uvfits&quot;))</code></pre><p>Now we do some minor preprocessing:</p><ul><li>Scan average the data since the data have been preprocessed so that the gain phases  are coherent.</li><li>Add 1% systematic noise to deal with calibration issues that cause 1% non-closing errors.</li></ul><pre><code class="language- hljs">obs = scan_average(obs).add_fractional_noise(0.01).flag_uvdist(uv_min=0.1e9)</code></pre><p>Now, we extract our closure quantities from the EHT data set.</p><pre><code class="language- hljs">dlcamp, dcphase  = extract_table(obs, LogClosureAmplitudes(;snrcut=3), ClosurePhases(;snrcut=3))</code></pre><h2 id="Build-the-Model/Posterior"><a class="docs-heading-anchor" href="#Build-the-Model/Posterior">Build the Model/Posterior</a><a id="Build-the-Model/Posterior-1"></a><a class="docs-heading-anchor-permalink" href="#Build-the-Model/Posterior" title="Permalink"></a></h2><p>For our model, we will be using an image model that consists of a raster of point sources, convolved with some pulse or kernel to make a <code>ContinuousImage</code> object with it <code>Comrade&#39;s.</code> generic image model. Note that <code>ContinuousImage(img, cache)</code> actually creates a <a href="../../api/#Comrade.ModelImage"><code>Comrade.ModelImage</code></a> object that allows <code>Comrade</code> to numerically compute the Fourier transform of the image.</p><pre><code class="language-julia hljs">function model(θ, metadata)
    (;c) = θ
    (; grid, cache) = metadata
    # Construct the image model
    c = to_simplex(CenteredLR(), c.params)
    img = IntensityMap(c, grid)
    return  ContinuousImage(img, cache)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">model (generic function with 1 method)</code></pre><p>Now, let&#39;s set up our image model. The EHT&#39;s nominal resolution is 20-25 μas. Additionally, the EHT is not very sensitive to a larger field of views; typically, 60-80 μas is enough to describe the compact flux of M87. Given this, we only need to use a small number of pixels to describe our image.</p><pre><code class="language- hljs">npix = 24
fovxy = μas2rad(100.0)</code></pre><p>Now, we can feed in the array information to form the cache</p><pre><code class="language- hljs">grid = imagepixels(fovxy, fovxy, npix, npix)
buffer = IntensityMap(zeros(npix,npix), grid)
cache = create_cache(NFFTAlg(dlcamp), buffer, BSplinePulse{3}())
metadata = (;grid, cache)</code></pre><p>Now we need to specify our image prior. For this work we will use a Gaussian Markov Random field prior</p><pre><code class="language- hljs">using VLBIImagePriors
using Distributions, DistributionsAD</code></pre><p>Since we are using a Gaussian Markov random field prior we need to first specify our <code>mean</code> image. For this work we will use a symmetric Gaussian with a FWHM of 40 μas</p><pre><code class="language- hljs">fwhmfac = 2*sqrt(2*log(2))
mpr = modify(Gaussian(), Stretch(μas2rad(40.0)./fwhmfac))
imgpr = intensitymap(mpr, grid)</code></pre><p>Now since we are actually modeling our image on the simplex we need to ensure that our mean image has unit flux</p><pre><code class="language- hljs">imgpr ./= flux(imgpr)

meanpr = to_real(CenteredLR(), Comrade.baseimage(imgpr))</code></pre><p>In addition we want a reasonable guess for what the resolution of our image should be. For radio astronomy this is given by roughly the longest baseline in the image. To put this into pixel space we then divide by the pixel size.</p><pre><code class="language- hljs">hh(x) = hypot(x...)
beam = inv(maximum(hh.(uvpositions.(extract_table(obs, ComplexVisibilities()).data))))
rat = (beam/(step(grid.X)))</code></pre><p>To make the Gaussian Markov random field efficient we first precompute a bunch of quantities that allow us to scale things linearly with the number of image pixels. This drastically improves the usual N^3 scaling you get from usual Gaussian Processes.</p><pre><code class="language- hljs">crcache = MarkovRandomFieldCache(meanpr)</code></pre><p>One of the benefits of the Bayesian approach is that we can fit for the hyperparameters of our prior/regularizers unlike traditional RML appraoches. To construct this heirarchical prior we will first make a map that takes in our regularizer hyperparameters and returns the image prior given those hyperparameters.</p><pre><code class="language- hljs">fmap = let meanpr=meanpr, crcache=crcache, rat=rat
    x-&gt;GaussMarkovRandomField(meanpr, x.λ/rat, x.σ*x.λ/rat, crcache)
end</code></pre><p>Now we can finally form our image prior. For this we use a heirarchical prior where the inverse correlation length is given by a Half-Normal distribution whose peak is at zero and standard deviation is 0.1/rat. For the variance of the GP we use another half normal prior with standard deviation unity. The reason we use the half-normal priors is to prefer &quot;simple&quot; structures. Namely, Gaussian Markov random fields are extremly flexible models. To prevent overfitting it is common to use priors that penalize complexity. Therefore, we want to use priors that enforce similarity to our mean image, and prefer smoothness.</p><pre><code class="language- hljs">cprior = HierarchicalPrior(fmap, Comrade.NamedDist((;λ = truncated(Normal(0.0, 1/3); lower=0.0), σ=truncated(Normal(0.0, 2.0); lower=0.0))))

prior = (c = cprior, )

lklhd = RadioLikelihood(model, dlcamp, dcphase;
                        skymeta = metadata)
post = Posterior(lklhd, prior)</code></pre><h2 id="Reconstructing-the-Image"><a class="docs-heading-anchor" href="#Reconstructing-the-Image">Reconstructing the Image</a><a id="Reconstructing-the-Image-1"></a><a class="docs-heading-anchor-permalink" href="#Reconstructing-the-Image" title="Permalink"></a></h2><p>To sample from this posterior, it is convenient to first move from our constrained parameter space to an unconstrained one (i.e., the support of the transformed posterior is (-∞, ∞)). This is done using the <code>asflat</code> function.</p><pre><code class="language- hljs">tpost = asflat(post)</code></pre><p>We can now also find the dimension of our posterior or the number of parameters we will sample.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This can often be different from what you would expect. This is especially true when using angular variables, where we often artificially increase the dimension of the parameter space to make sampling easier.</p></div></div><pre><code class="language- hljs">ndim = dimension(tpost)</code></pre><p>Now we optimize using LBFGS</p><pre><code class="language- hljs">using ComradeOptimization
using OptimizationOptimJL
using Zygote
f = OptimizationFunction(tpost, Optimization.AutoZygote())
prob = Optimization.OptimizationProblem(f, prior_sample(rng, tpost), nothing)
sol = solve(prob, LBFGS(); maxiters=5_000);
nothing #hide</code></pre><p>Before we analyze our solution we first need to transform back to parameter space.</p><pre><code class="language- hljs">xopt = transform(tpost, sol)</code></pre><p>First we will evaluate our fit by plotting the residuals</p><pre><code class="language- hljs">using Plots
residual(skymodel(post, xopt), dlcamp)
residual(skymodel(post, xopt), dcphase)</code></pre><p>Now these residuals look a bit high. However, it turns out this is because the MAP is typically not a great estimator and will not provide very predictive measurements of the data. We will show this below after sampling from the posterior.</p><pre><code class="language- hljs">img = intensitymap(skymodel(post, xopt), μas2rad(120.0), μas2rad(120.0), 128, 128)
plot(img, title=&quot;MAP Image&quot;)</code></pre><p>To sample from the posterior we will use HMC and more specifically the NUTS algorithm. For information about NUTS see Michael Betancourt&#39;s <a href="https://arxiv.org/abs/1701.02434">notes</a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For our <code>metric</code> we use a diagonal matrix due to easier tuning.</p></div></div><pre><code class="language- hljs">using ComradeAHMC
using Zygote
metric = DiagEuclideanMetric(ndim)
chain, stats = sample(post, AHMC(;metric, autodiff=Val(:Zygote)), 1_000; nadapts=500, init_params=xopt)</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This should be run for ;longer!</p></div></div><p>Now that we have our posterior, we can assess which parts of the image are strongly inferred by the data. This is rather unique to <code>Comrade</code> where more traditional imaging algorithms like CLEAN and RML are inherently unable to assess uncertainty in their reconstructions.</p><p>To explore our posterior let&#39;s first create images from a bunch of draws from the posterior</p><pre><code class="language- hljs">msamples = skymodel.(Ref(post), chain[500:5:end]);
nothing #hide</code></pre><p>The mean image is then given by</p><pre><code class="language- hljs">using StatsBase
imgs = intensitymap.(msamples, μas2rad(100.0), μas2rad(100.0), 128, 128)
mimg = mean(imgs)
simg = std(imgs)
p1 = plot(mimg, title=&quot;Mean Image&quot;)
p2 = plot(simg./mimg, title=&quot;1/SNR&quot;)
p3 = plot(imgs[1], title=&quot;Draw 1&quot;)
p4 = plot(imgs[end], title=&quot;Draw 2&quot;)
plot(p1, p2, p3, p4, size=(800,800), colorbar=:none)</code></pre><p>Now let&#39;s see whether our residuals look better.</p><pre><code class="language- hljs">p = plot();
c2 = 0.0
for s in sample(chain[501:end], 10)
    c2 += chi2(vlbimodel(post, s), dlcamp)/(2*length(dlcamp))
    residual!(p, vlbimodel(post, s), dlcamp)
end
title!(p, &quot;&lt;χ²&gt; = $(c2/10)&quot;);
ylabel!(&quot;Log-Closure Amplitude Res.&quot;);
p


p = plot();
c2 = 0.0
for s in sample(chain[501:end], 10)
    c2 += chi2(vlbimodel(post, s), dcphase)/(2*length(dcphase))
    residual!(p, vlbimodel(post, s), dcphase)
end
title!(p, &quot;&lt;χ²&gt; = $(c2/10)&quot;);
ylabel!(&quot;Closure Phase Res.&quot;);
p</code></pre><p>And we see that the residuals are looking much better.</p><p>And viola, you have a quick and preliminary image of M87 fitting only closure products. For a publication-level version we would recommend</p><ol><li>Running the chain longer and multiple times to properly assess things like ESS and R̂ (see <a href="../geometric_modeling/#Geometric-Modeling-of-EHT-Data">Geometric Modeling of EHT Data</a>)</li><li>Fitting gains. Typically gain amplitudes are good to 10-20% for the EHT not the infinite uncertainty closures implicitly assume</li><li>Making sure the posterior is unimodal (hint for this example it isn&#39;t!). The EHT image posteriors can be pretty complicated, so typically you want to use a sampler that can deal with multi-modal posteriors. Check out the package <a href="https://github.com/Julia-Tempering/Pigeons.jl"><code>Pigeons.jl</code></a> for an <strong>in-development</strong> package that should easily enable this type of sampling.</li></ol><h2 id="Computing-information"><a class="docs-heading-anchor" href="#Computing-information">Computing information</a><a id="Computing-information-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-information" title="Permalink"></a></h2><pre><code class="nohighlight hljs">Julia Version 1.8.5
Commit 17cfb8e65ea (2023-01-08 06:45 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: 32 × AMD Ryzen 9 7950X 16-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-13.0.1 (ORCJIT, znver3)
  Threads: 1 on 32 virtual cores
Environment:
  JULIA_EDITOR = code
  JULIA_NUM_THREADS = 1</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../geometric_modeling/">« Geometric Modeling of EHT Data</a><a class="docs-footer-nextpage" href="../imaging_vis/">Stokes I Simultaneous Image and Instrument Modeling »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 5 June 2023 04:20">Monday 5 June 2023</span>. Using Julia version 1.9.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
