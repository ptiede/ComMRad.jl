<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Stokes I Simultaneous Image and Instrument Modeling · Comrade.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Comrade.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../benchmarks/">Benchmarks</a></li><li><a class="tocitem" href="../../vlbi_imaging_problem/">Introduction to the VLBI Imaging Problem</a></li><li><a class="tocitem" href="../../conventions/">Conventions</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../data/">Loading Data into Comrade</a></li></ul></li><li><span class="tocitem">Libraries</span><ul><li><a class="tocitem" href="../../libs/optimization/">ComradeOptimization</a></li><li><a class="tocitem" href="../../libs/ahmc/">ComradeAHMC</a></li><li><a class="tocitem" href="../../libs/nested/">ComradeNested</a></li><li><a class="tocitem" href="../../libs/dynesty/">ComradeDynesty</a></li><li><a class="tocitem" href="../../libs/adaptmcmc/">ComradeAdaptMCMC</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Stokes I Simultaneous Image and Instrument Modeling</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Stokes I Simultaneous Image and Instrument Modeling</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ptiede/Comrade.jl/blob/main/examples/imaging_vis.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Stokes-I-Simultaneous-Image-and-Instrument-Modeling"><a class="docs-heading-anchor" href="#Stokes-I-Simultaneous-Image-and-Instrument-Modeling">Stokes I Simultaneous Image and Instrument Modeling</a><a id="Stokes-I-Simultaneous-Image-and-Instrument-Modeling-1"></a><a class="docs-heading-anchor-permalink" href="#Stokes-I-Simultaneous-Image-and-Instrument-Modeling" title="Permalink"></a></h1><p>In this tutorial, we will create a preliminary reconstruction of the 2017 M87 data on April 6 by simultaneously creating an image and model for the instrument. By instrument model, we mean something akin to self-calibration in traditional VLBI imaging terminology. However, unlike traditional self-cal, we will at each point in our parameter space effectively explore the possible self-cal solutions. This will allow us to constrain and marginalize over the instrument effects, such as time variable gains.</p><p>To get started we load Comrade.</p><pre><code class="language-julia hljs">using Comrade</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">  Activating project at `~/work/Comrade.jl/Comrade.jl/examples`</code></pre><p>For reproducibility we use a stable random number genreator</p><pre><code class="language-julia hljs">using StableRNGs
rng = StableRNG(124)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">StableRNGs.LehmerRNG(state=0x000000000000000000000000000000f9)</code></pre><h2 id="Load-the-Data"><a class="docs-heading-anchor" href="#Load-the-Data">Load the Data</a><a id="Load-the-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Load-the-Data" title="Permalink"></a></h2><p>To download the data visit https://doi.org/10.25739/g85n-f134 First we will load our data:</p><pre><code class="language-julia hljs">obs = load_ehtim_uvfits(joinpath(dirname(pathof(Comrade)), &quot;..&quot;, &quot;examples&quot;, &quot;SR1_M87_2017_096_hi_hops_netcal_StokesI.uvfits&quot;))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Python Obsdata: &lt;ehtim.obsdata.Obsdata object at 0x7f2fd0f860b0&gt;</code></pre><p>Now we do some minor preprocessing:</p><ul><li>Scan average the data since the data have been preprocessed so that the gain phases  coherent.</li><li>Add 1% systematic noise to deal with calibration issues that cause 1% non-closing errors.</li></ul><pre><code class="language-julia hljs">obs = scan_average(obs.add_fractional_noise(0.01))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Python Obsdata: &lt;ehtim.obsdata.Obsdata object at 0x7f301ef3a410&gt;</code></pre><p>Now we extract our complex visibilities.</p><pre><code class="language-julia hljs">dvis = extract_vis(obs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">EHTObservation{Float64,Comrade.EHTVisibilityDatum{Float64}, ...}
  source: M87
  mjd: 57849
  frequency: 2.29070703125e11
  bandwidth: 1.856e9
  stations: [:AA, :AP, :AZ, :JC, :LM, :PV, :SM]
  nsamples: 284
</code></pre><p>##Building the Model/Posterior</p><p>Now, we must build our intensity/visibility model. That is, the model that takes in a named tuple of parameters and perhaps some metadata required to construct the model. For our model, we will use a raster or <code>ContinuousImage</code> for our image model. Unlike other imaging examples (e.g., <a href="../imaging_closures/#Imaging-a-Black-Hole-using-only-Closure-Quantities">Imaging a Black Hole using only Closure Quantities</a>) we also need to include a model for the instrument, i.e., gains as well. The gains will be broken into two components</p><ul><li>Gain amplitudes which are typically known to 10-20%, except for LMT, which has amplitudes closer to 50-100%.</li><li>Gain phases which are more difficult to constrain and can shift rapidly.</li></ul><p>The model is given below:</p><pre><code class="language-julia hljs">function model(θ, metadata)
    (;fg, c, lgamp, gphase) = θ
    (; grid, cache, gcache, gcachep) = metadata
    # Construct the image model we fix the flux to 0.6 Jy in this case
    img = IntensityMap((1.1*(1-fg)).*c, grid)
    m = ContinuousImage(img,cache)
    g = modify(Gaussian(), Stretch(μas2rad(250.0), μas2rad(250.0)), Renormalize(1.1*fg))
    # Now form our instrument model
    gvis = exp.(lgamp)
    gphase = exp.(1im.*gphase)
    jgamp = jonesStokes(gvis, gcache)
    jgphase = jonesStokes(gphase, gcachep)
    return JonesModel(jgamp*jgphase, m+g)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">model (generic function with 1 method)</code></pre><p>The model construction is very similar to <a href="../imaging_closures/#Imaging-a-Black-Hole-using-only-Closure-Quantities">Imaging a Black Hole using only Closure Quantities</a>, except we fix the compact flux to 0.6 Jy for simplicity in this run. For more information about the image model please read the closure-only example. Let&#39;s discuss the instrument model <a href="../../api/#Comrade.JonesModel"><code>JonesModel</code></a>. Thanks to the EHT pre-calibration, the gains are stable over scans. Therefore, we can model the gains on a scan-by-scan basis. To form the instrument model, we need our</p><ol><li>Our (log) gain amplitudes and phases are given below by <code>lgamp</code> and <code>gphase</code></li><li>Our function or cache that maps the gains from a list to the stations they impact <code>gcache.</code></li><li>The set of <a href="../../api/#Comrade.JonesPairs"><code>Comrade.JonesPairs</code></a> produced by <a href="../../api/#Comrade.jonesStokes"><code>jonesStokes</code></a></li></ol><p>These three ingredients then specify our instrument model. The instrument model can then be combined with our image model <code>cimg</code> to form the total <code>JonesModel</code>.</p><p>Now, let&#39;s set up our image model. The EHT&#39;s nominal resolution is 20-25 μas. Additionally, the EHT is not very sensitive to a larger field of view. Typically 60-80 μas is enough to describe the compact flux of M87. Given this, we only need to use a small number of pixels to describe our image.</p><pre><code class="language-julia hljs">npix = 32
fovx = μas2rad(65.0)
fovy = μas2rad(65.0)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3.151288927211984e-10</code></pre><p>Now let&#39;s form our cache&#39;s. First, we have our usual image cache which is needed to numerically compute the visibilities.</p><pre><code class="language-julia hljs">grid = imagepixels(fovx, fovy, npix, npix)
buffer = IntensityMap(zeros(npix, npix), grid)
cache = create_cache(NFFTAlg(dvis), buffer, BSplinePulse{3}())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Comrade.NUFTCache{Comrade.ObservedNUFT{NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}, Matrix{Float64}}, NFFT.NFFTPlan{Float64, 2, 1}, Vector{ComplexF64}, BSplinePulse{3}, AxisKeys.KeyedArray{Float64, 2, NamedDims.NamedDimsArray{(:X, :Y), Float64, 2, Matrix{Float64}}, GriddedKeys{(:X, :Y), Tuple{LinRange{Float64, Int64}, LinRange{Float64, Int64}}, Nothing, Float64}}}(Comrade.ObservedNUFT{NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}, Matrix{Float64}}(NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}(1, 4, 2.0, :kaiser_bessel, AbstractNFFTs.TENSOR, true, false, true, 0x00000000), [1.2065151329523807e9 819926.8691406249 … 4.472903950222221e9 -15688.352240668402; -3.8185738483809524e9 -1.7123166484375e6 … -6.2063795222222224e7 119336.55902777778]), NFFTPlan with 284 sampling points for an input array of size(32, 32) and an output array of size(284,) with dims 1:2, ComplexF64[0.9865844099884237 - 0.07990098290052436im, 0.9999999973189964 - 2.7608493184361647e-5im, 0.9368362937311634 - 0.268038779688234im, 0.98659609859411 + 0.07987439990219439im, 0.9602706516114454 + 0.1927876539950377im, 0.9368485304205844 + 0.26801464705017597im, 0.9999999973648531 - 2.7971608464344617e-5im, 0.9352583598405778 - 0.27117329016844127im, 0.9868409691066048 - 0.07493245540240043im, 0.9868525374617463 + 0.07490574518181693im  …  0.9667705664002574 + 0.08903690820496529im, 0.9667709477967955 + 0.0890400125877865im, 0.984120120416588 + 0.04264428457331327im, 0.9830029522603712 + 0.13375293877338076im, 0.9830024380289504 + 0.13375611932343884im, 0.9915939491136283 + 0.0441373293956296im, 0.9781263498607656 + 0.1343078739056269im, 0.9985754549294115 + 0.0012211426653648883im, 0.9781260112249708 + 0.13431106258822434im, 0.9999999999856142 + 3.206637821223534e-6im], BSplinePulse{3}(), [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0])</code></pre><p>Second, we now construct our instrument model cache. This tells us how to map from the gains to the model visibilities. However, to construct this map, we also need to specify the observation segmentation over which we expect the gains to change. This is specified in the second argument to <code>jonescache</code>, and currently, there are two options</p><ul><li><code>FixedSeg(val)</code>: Fixes the corruption to the value <code>val</code> for all time. This is usefule for reference stations</li><li><code>ScanSeg()</code>: which forces the corruptions to only change from scan-to-scan</li><li><code>TrackSeg()</code>: which forces the corruptions to be constant over a night&#39;s observation</li></ul><p>For this work, we use the scan segmentation for the gain amplitudes since that is roughly the timescale we expect them to vary. For the phases we use a station specific scheme where we set AA to be fixed to unit gain because it will function as a reference station.</p><pre><code class="language-julia hljs">gcache = jonescache(dvis, ScanSeg())
segs = (AA = FixedSeg(1.0 + 0.0im),
        AP = ScanSeg(),
        AZ = ScanSeg(),
        JC = ScanSeg(),
        LM = ScanSeg(),
        PV = ScanSeg(),
        SM = ScanSeg())
gcachep = jonescache(dvis, segs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}(sparse([4, 5, 6, 10, 11, 12, 16, 17, 18, 22  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [2, 3, 3, 5, 6, 6, 8, 9, 9, 11  …  101, 101, 102, 102, 102, 104, 104, 104, 104, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105),   [1  ]  =  1.0+0.0im
  [2  ]  =  1.0+0.0im
  [3  ]  =  1.0+0.0im
  [7  ]  =  1.0+0.0im
  [8  ]  =  1.0+0.0im
  [9  ]  =  1.0+0.0im
  [13 ]  =  1.0+0.0im
         ⋮
  [257]  =  1.0+0.0im
  [258]  =  1.0+0.0im
  [259]  =  1.0+0.0im
  [270]  =  1.0+0.0im
  [271]  =  1.0+0.0im
  [272]  =  1.0+0.0im
  [273]  =  1.0+0.0im
  [274]  =  1.0+0.0im), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [1, 1, 1, 2, 2, 3, 4, 4, 4, 5  …  103, 103, 103, 103, 103, 104, 105, 105, 105, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105), (AA = FixedSeg{ComplexF64}(1.0 + 0.0im), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AP, :LM, :PV, :AP, :LM, :PV, :AP, :LM, :PV, :AP  …  :AP, :AZ, :JC, :LM, :SM, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256, 1.516666665673256, 1.816666603088379  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AP), (1.516666665673256, :LM), (1.516666665673256, :PV), (1.816666603088379, :AP)  …  (7.7166666984558105, :AP), (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)]))</code></pre><p>Now we can form our metadata we need to fully define our model.</p><pre><code class="language-julia hljs">metadata = (;grid, cache, gcache, gcachep)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(grid = GriddedKeys{(:X, :Y)}
	X: LinRange{Float64}(-1.5264055741183046e-10, 1.5264055741183046e-10, 32)
	Y: LinRange{Float64}(-1.5264055741183046e-10, 1.5264055741183046e-10, 32)
, cache = Comrade.NUFTCache{Comrade.ObservedNUFT{NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}, Matrix{Float64}}, NFFT.NFFTPlan{Float64, 2, 1}, Vector{ComplexF64}, BSplinePulse{3}, AxisKeys.KeyedArray{Float64, 2, NamedDims.NamedDimsArray{(:X, :Y), Float64, 2, Matrix{Float64}}, GriddedKeys{(:X, :Y), Tuple{LinRange{Float64, Int64}, LinRange{Float64, Int64}}, Nothing, Float64}}}(Comrade.ObservedNUFT{NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}, Matrix{Float64}}(NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}(1, 4, 2.0, :kaiser_bessel, AbstractNFFTs.TENSOR, true, false, true, 0x00000000), [1.2065151329523807e9 819926.8691406249 … 4.472903950222221e9 -15688.352240668402; -3.8185738483809524e9 -1.7123166484375e6 … -6.2063795222222224e7 119336.55902777778]), NFFTPlan with 284 sampling points for an input array of size(32, 32) and an output array of size(284,) with dims 1:2, ComplexF64[0.9865844099884237 - 0.07990098290052436im, 0.9999999973189964 - 2.7608493184361647e-5im, 0.9368362937311634 - 0.268038779688234im, 0.98659609859411 + 0.07987439990219439im, 0.9602706516114454 + 0.1927876539950377im, 0.9368485304205844 + 0.26801464705017597im, 0.9999999973648531 - 2.7971608464344617e-5im, 0.9352583598405778 - 0.27117329016844127im, 0.9868409691066048 - 0.07493245540240043im, 0.9868525374617463 + 0.07490574518181693im  …  0.9667705664002574 + 0.08903690820496529im, 0.9667709477967955 + 0.0890400125877865im, 0.984120120416588 + 0.04264428457331327im, 0.9830029522603712 + 0.13375293877338076im, 0.9830024380289504 + 0.13375611932343884im, 0.9915939491136283 + 0.0441373293956296im, 0.9781263498607656 + 0.1343078739056269im, 0.9985754549294115 + 0.0012211426653648883im, 0.9781260112249708 + 0.13431106258822434im, 0.9999999999856142 + 3.206637821223534e-6im], BSplinePulse{3}(), [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]), gcache = JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(sparse([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [1, 1, 1, 3, 4, 4, 5, 5, 5, 7  …  125, 125, 126, 126, 126, 128, 128, 128, 128, 129], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 129), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [2, 2, 2, 3, 3, 4, 6, 6, 6, 7  …  127, 127, 127, 127, 127, 128, 129, 129, 129, 129], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 129), (AA = ScanSeg{false}(), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AA, :AP, :LM, :PV, :AA, :AP, :LM, :PV, :AA, :AP  …  :AZ, :JC, :LM, :SM, :AA, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AA), (0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AA), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AA), (1.516666665673256, :AP)  …  (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AA), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)])), gcachep = JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}(sparse([4, 5, 6, 10, 11, 12, 16, 17, 18, 22  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [2, 3, 3, 5, 6, 6, 8, 9, 9, 11  …  101, 101, 102, 102, 102, 104, 104, 104, 104, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105),   [1  ]  =  1.0+0.0im
  [2  ]  =  1.0+0.0im
  [3  ]  =  1.0+0.0im
  [7  ]  =  1.0+0.0im
  [8  ]  =  1.0+0.0im
  [9  ]  =  1.0+0.0im
  [13 ]  =  1.0+0.0im
         ⋮
  [257]  =  1.0+0.0im
  [258]  =  1.0+0.0im
  [259]  =  1.0+0.0im
  [270]  =  1.0+0.0im
  [271]  =  1.0+0.0im
  [272]  =  1.0+0.0im
  [273]  =  1.0+0.0im
  [274]  =  1.0+0.0im), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [1, 1, 1, 2, 2, 3, 4, 4, 4, 5  …  103, 103, 103, 103, 103, 104, 105, 105, 105, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105), (AA = FixedSeg{ComplexF64}(1.0 + 0.0im), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AP, :LM, :PV, :AP, :LM, :PV, :AP, :LM, :PV, :AP  …  :AP, :AZ, :JC, :LM, :SM, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256, 1.516666665673256, 1.816666603088379  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AP), (1.516666665673256, :LM), (1.516666665673256, :PV), (1.816666603088379, :AP)  …  (7.7166666984558105, :AP), (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)])))</code></pre><p>Moving onto our prior, we first focus on the instrument model priors. Each station requires its own prior on both the amplitudes and phases. For the amplitudes we assume that the gains are apriori well calibrated around unit gains (or 0 log gain amplitudes) which corresponds to no instrument corruption. The gain dispersion is then set to 10% for all stations except LMT, representing that we expect 10% deviations from scan-to-scan. For LMT we let the prior expand to 100% due to the known pointing issues LMT had in 2017.</p><pre><code class="language-julia hljs">using Distributions
using DistributionsAD
distamp = (AA = Normal(0.0, 0.1),
           AP = Normal(0.0, 0.1),
           LM = Normal(0.0, 1.0),
           AZ = Normal(0.0, 0.1),
           JC = Normal(0.0, 0.1),
           PV = Normal(0.0, 0.1),
           SM = Normal(0.0, 0.1),
           )</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(AA = Distributions.Normal{Float64}(μ=0.0, σ=0.1), AP = Distributions.Normal{Float64}(μ=0.0, σ=0.1), LM = Distributions.Normal{Float64}(μ=0.0, σ=1.0), AZ = Distributions.Normal{Float64}(μ=0.0, σ=0.1), JC = Distributions.Normal{Float64}(μ=0.0, σ=0.1), PV = Distributions.Normal{Float64}(μ=0.0, σ=0.1), SM = Distributions.Normal{Float64}(μ=0.0, σ=0.1))</code></pre><p>For the phases, as mentioned above, we will use a segmented gain prior. This means that rather than the parameters being directly the gains, we fit the first gain for each site, and then the other parameters are the segmented gains compared to the previous time. To model this</p><pre><code class="language-julia hljs">#, we break the gain phase prior into two parts. The first is the prior</code></pre><p>for the first observing timestamp of each site, <code>distphase0</code>, and the second is the prior for segmented gain ϵₜ from time i to i+1, given by <code>distphase</code>. For the EHT, we are dealing with pre-2*rand(rng, ndim) .- 1.5calibrated data, so often, the gain phase jumps from scan to scan are minor. As such, we can put a more informative prior on <code>distphase</code>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>We use AA (ALMA) as a reference station so we do not have to specify a gain prior for it.</p></div></div><pre><code class="language-julia hljs">using VLBIImagePriors

distphase = (
             AP = DiagonalVonMises(0.0, inv(π^2)),
             LM = DiagonalVonMises(0.0, inv(π^2)),
             AZ = DiagonalVonMises(0.0, inv(π^2)),
             JC = DiagonalVonMises(0.0, inv(π^2)),
             PV = DiagonalVonMises(0.0, inv(π^2)),
             SM = DiagonalVonMises(0.0, inv(π^2)),
           )</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(AP = VLBIImagePriors.DiagonalVonMises{Float64, Float64, Float64}(μ=0.0, κ=0.10132118364233778, lnorm=-1.739120733481688), LM = VLBIImagePriors.DiagonalVonMises{Float64, Float64, Float64}(μ=0.0, κ=0.10132118364233778, lnorm=-1.739120733481688), AZ = VLBIImagePriors.DiagonalVonMises{Float64, Float64, Float64}(μ=0.0, κ=0.10132118364233778, lnorm=-1.739120733481688), JC = VLBIImagePriors.DiagonalVonMises{Float64, Float64, Float64}(μ=0.0, κ=0.10132118364233778, lnorm=-1.739120733481688), PV = VLBIImagePriors.DiagonalVonMises{Float64, Float64, Float64}(μ=0.0, κ=0.10132118364233778, lnorm=-1.739120733481688), SM = VLBIImagePriors.DiagonalVonMises{Float64, Float64, Float64}(μ=0.0, κ=0.10132118364233778, lnorm=-1.739120733481688))</code></pre><p>We can now form our model parameter priors. Like our other imaging examples, we use a Dirichlet prior for our image pixels. For the log gain amplitudes, we use the <code>CalPrior</code> which automatically constructs the prior for the given jones cache <code>gcache</code>.</p><pre><code class="language-julia hljs">(;X, Y) = grid
prior = (
         fg = Uniform(0.0, 1.0),
         c = ImageDirichlet(1.0, npix, npix),
         lgamp = CalPrior(distamp, gcache),
         gphase = CalPrior(distphase, gcachep),
        )</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(fg = Distributions.Uniform{Float64}(a=0.0, b=1.0), c = VLBIImagePriors.ImageDirichlet{Float64, FillArrays.Fill{Float64, 2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Float64}(
α: Fill(1.0, 32, 32)
α0: 1024.0
lmnB: -6071.28041294445
)
, lgamp = CalPrior{Distributions.DiagNormal, JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}(
dists: DiagNormal(
dim: 129
μ: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Σ: [0.010000000000000002 0.0 … 0.0 0.0; 0.0 0.010000000000000002 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 0.010000000000000002]
)

jcache: JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(sparse([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [1, 1, 1, 3, 4, 4, 5, 5, 5, 7  …  125, 125, 126, 126, 126, 128, 128, 128, 128, 129], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 129), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [2, 2, 2, 3, 3, 4, 6, 6, 6, 7  …  127, 127, 127, 127, 127, 128, 129, 129, 129, 129], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 129), (AA = ScanSeg{false}(), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AA, :AP, :LM, :PV, :AA, :AP, :LM, :PV, :AA, :AP  …  :AZ, :JC, :LM, :SM, :AA, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AA), (0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AA), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AA), (1.516666665673256, :AP)  …  (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AA), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)]))
)
, gphase = CalPrior{VLBIImagePriors.DiagonalVonMises{Vector{Float64}, Vector{Float64}, Float64}, JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}(
dists: VLBIImagePriors.DiagonalVonMises{Vector{Float64}, Vector{Float64}, Float64}(
μ: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
κ: [0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778  …  0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778]
lnorm: -182.60767701557722
)

jcache: JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}(sparse([4, 5, 6, 10, 11, 12, 16, 17, 18, 22  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [2, 3, 3, 5, 6, 6, 8, 9, 9, 11  …  101, 101, 102, 102, 102, 104, 104, 104, 104, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105),   [1  ]  =  1.0+0.0im
  [2  ]  =  1.0+0.0im
  [3  ]  =  1.0+0.0im
  [7  ]  =  1.0+0.0im
  [8  ]  =  1.0+0.0im
  [9  ]  =  1.0+0.0im
  [13 ]  =  1.0+0.0im
         ⋮
  [257]  =  1.0+0.0im
  [258]  =  1.0+0.0im
  [259]  =  1.0+0.0im
  [270]  =  1.0+0.0im
  [271]  =  1.0+0.0im
  [272]  =  1.0+0.0im
  [273]  =  1.0+0.0im
  [274]  =  1.0+0.0im), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [1, 1, 1, 2, 2, 3, 4, 4, 4, 5  …  103, 103, 103, 103, 103, 104, 105, 105, 105, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105), (AA = FixedSeg{ComplexF64}(1.0 + 0.0im), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AP, :LM, :PV, :AP, :LM, :PV, :AP, :LM, :PV, :AP  …  :AP, :AZ, :JC, :LM, :SM, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256, 1.516666665673256, 1.816666603088379  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AP), (1.516666665673256, :LM), (1.516666665673256, :PV), (1.816666603088379, :AP)  …  (7.7166666984558105, :AP), (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)]))
)
)</code></pre><p>Putting it all together we form our likelihood and posterior objects for optimization and sampling.</p><pre><code class="language-julia hljs">lklhd = RadioLikelihood(model, metadata, dvis)
post = Posterior(lklhd, prior)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Posterior{RadioLikelihood{Comrade.ModelMetadata{typeof(Main.model), NamedTuple{(:grid, :cache, :gcache, :gcachep), Tuple{GriddedKeys{(:X, :Y), Tuple{LinRange{Float64, Int64}, LinRange{Float64, Int64}}, Nothing, Float64}, Comrade.NUFTCache{Comrade.ObservedNUFT{NFFTAlg{Float64, AbstractNFFTs.PrecomputeFlags, UInt32}, Matrix{Float64}}, NFFT.NFFTPlan{Float64, 2, 1}, Vector{ComplexF64}, BSplinePulse{3}, AxisKeys.KeyedArray{Float64, 2, NamedDims.NamedDimsArray{(:X, :Y), Float64, 2, Matrix{Float64}}, GriddedKeys{(:X, :Y), Tuple{LinRange{Float64, Int64}, LinRange{Float64, Int64}}, Nothing, Float64}}}, JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}, JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}}}, Tuple{Comrade.ConditionedLikelihood{Comrade.var&quot;#65#66&quot;{Vector{Float64}}, Vector{ComplexF64}}}, Comrade.EHTArrayConfiguration{Float64, TypedTables.Table{NamedTuple{(:sites, :X, :Y, :Z, :SEFD1, :SEFD2, :fr_parallactic, :fr_elevation, :fr_offset), Tuple{Symbol, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}}, 1, NamedTuple{(:sites, :X, :Y, :Z, :SEFD1, :SEFD2, :fr_parallactic, :fr_elevation, :fr_offset), Tuple{Vector{Symbol}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}}}}, TypedTables.Table{NamedTuple{(:start, :stop), Tuple{Float64, Float64}}, 1, NamedTuple{(:start, :stop), Tuple{Vector{Float64}, Vector{Float64}}}}, StructArrays.StructVector{Comrade.ArrayBaselineDatum, NamedTuple{(:U, :V, :T, :F, :baseline, :error, :elevation, :parallactic), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Tuple{Symbol, Symbol}}, Vector{Float64}, StructArrays.StructVector{Tuple{Float64, Float64}, Tuple{Vector{Float64}, Vector{Float64}}, Int64}, StructArrays.StructVector{Tuple{Float64, Float64}, Tuple{Vector{Float64}, Vector{Float64}}, Int64}}}, Int64}}, NamedTuple{(:U, :V, :T, :F), NTuple{4, Vector{Float64}}}}, Comrade.NamedDist{(:fg, :c, :lgamp, :gphase), Tuple{Distributions.Uniform{Float64}, VLBIImagePriors.ImageDirichlet{Float64, FillArrays.Fill{Float64, 2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Float64}, CalPrior{Distributions.DiagNormal, JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}, CalPrior{VLBIImagePriors.DiagonalVonMises{Vector{Float64}, Vector{Float64}, Float64}, JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}}}}(RadioLikelihood
	Number of data products: 1
, Comrade.NamedDist{(:fg, :c, :lgamp, :gphase), Tuple{Distributions.Uniform{Float64}, VLBIImagePriors.ImageDirichlet{Float64, FillArrays.Fill{Float64, 2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Float64}, CalPrior{Distributions.DiagNormal, JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}, CalPrior{VLBIImagePriors.DiagonalVonMises{Vector{Float64}, Vector{Float64}, Float64}, JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}}}((Distributions.Uniform{Float64}(a=0.0, b=1.0), VLBIImagePriors.ImageDirichlet{Float64, FillArrays.Fill{Float64, 2, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}, Float64}(
α: Fill(1.0, 32, 32)
α0: 1024.0
lmnB: -6071.28041294445
)
, CalPrior{Distributions.DiagNormal, JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}(
dists: DiagNormal(
dim: 129
μ: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Σ: [0.010000000000000002 0.0 … 0.0 0.0; 0.0 0.010000000000000002 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 0.010000000000000002]
)

jcache: JonesCache{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), NTuple{7, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(sparse([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [1, 1, 1, 3, 4, 4, 5, 5, 5, 7  …  125, 125, 126, 126, 126, 128, 128, 128, 128, 129], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 129), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [2, 2, 2, 3, 3, 4, 6, 6, 6, 7  …  127, 127, 127, 127, 127, 128, 129, 129, 129, 129], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 129), (AA = ScanSeg{false}(), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AA, :AP, :LM, :PV, :AA, :AP, :LM, :PV, :AA, :AP  …  :AZ, :JC, :LM, :SM, :AA, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AA), (0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AA), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AA), (1.516666665673256, :AP)  …  (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AA), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)]))
)
, CalPrior{VLBIImagePriors.DiagonalVonMises{Vector{Float64}, Vector{Float64}, Float64}, JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}}(
dists: VLBIImagePriors.DiagonalVonMises{Vector{Float64}, Vector{Float64}, Float64}(
μ: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
κ: [0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778  …  0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778, 0.10132118364233778]
lnorm: -182.60767701557722
)

jcache: JonesCache{Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}, SparseArrays.SparseMatrixCSC{Float64, Int64}, NamedTuple{(:AA, :AP, :AZ, :JC, :LM, :PV, :SM), Tuple{FixedSeg{ComplexF64}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}, ScanSeg{false}}}, Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}}(Comrade.AffineDesignMatrix{SparseArrays.SparseMatrixCSC{Float64, Int64}, SparseArrays.SparseVector{ComplexF64, Int64}}(sparse([4, 5, 6, 10, 11, 12, 16, 17, 18, 22  …  275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [2, 3, 3, 5, 6, 6, 8, 9, 9, 11  …  101, 101, 102, 102, 102, 104, 104, 104, 104, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105),   [1  ]  =  1.0+0.0im
  [2  ]  =  1.0+0.0im
  [3  ]  =  1.0+0.0im
  [7  ]  =  1.0+0.0im
  [8  ]  =  1.0+0.0im
  [9  ]  =  1.0+0.0im
  [13 ]  =  1.0+0.0im
         ⋮
  [257]  =  1.0+0.0im
  [258]  =  1.0+0.0im
  [259]  =  1.0+0.0im
  [270]  =  1.0+0.0im
  [271]  =  1.0+0.0im
  [272]  =  1.0+0.0im
  [273]  =  1.0+0.0im
  [274]  =  1.0+0.0im), sparse([2, 4, 6, 1, 5, 3, 7, 10, 12, 9  …  274, 276, 279, 283, 284, 272, 271, 275, 278, 281], [1, 1, 1, 2, 2, 3, 4, 4, 4, 5  …  103, 103, 103, 103, 103, 104, 105, 105, 105, 105], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 284, 105), (AA = FixedSeg{ComplexF64}(1.0 + 0.0im), AP = ScanSeg{false}(), AZ = ScanSeg{false}(), JC = ScanSeg{false}(), LM = ScanSeg{false}(), PV = ScanSeg{false}(), SM = ScanSeg{false}()), Comrade.GainSchema{Vector{Symbol}, Vector{Float64}, Vector{Tuple{Float64, Symbol}}}([:AP, :LM, :PV, :AP, :LM, :PV, :AP, :LM, :PV, :AP  …  :AP, :AZ, :JC, :LM, :SM, :AP, :AZ, :JC, :LM, :SM], [0.9166666567325592, 0.9166666567325592, 0.9166666567325592, 1.2166666388511658, 1.2166666388511658, 1.2166666388511658, 1.516666665673256, 1.516666665673256, 1.516666665673256, 1.816666603088379  …  7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.7166666984558105, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905, 7.983333349227905], [(0.9166666567325592, :AP), (0.9166666567325592, :LM), (0.9166666567325592, :PV), (1.2166666388511658, :AP), (1.2166666388511658, :LM), (1.2166666388511658, :PV), (1.516666665673256, :AP), (1.516666665673256, :LM), (1.516666665673256, :PV), (1.816666603088379, :AP)  …  (7.7166666984558105, :AP), (7.7166666984558105, :AZ), (7.7166666984558105, :JC), (7.7166666984558105, :LM), (7.7166666984558105, :SM), (7.983333349227905, :AP), (7.983333349227905, :AZ), (7.983333349227905, :JC), (7.983333349227905, :LM), (7.983333349227905, :SM)]))
)
)))</code></pre><h2 id="Reconstructing-the-Image-and-Instrument-Effects"><a class="docs-heading-anchor" href="#Reconstructing-the-Image-and-Instrument-Effects">Reconstructing the Image and Instrument Effects</a><a id="Reconstructing-the-Image-and-Instrument-Effects-1"></a><a class="docs-heading-anchor-permalink" href="#Reconstructing-the-Image-and-Instrument-Effects" title="Permalink"></a></h2><p>To sample from this posterior, it is convenient to move from our constrained parameter space to an unconstrained one (i.e., the support of the transformed posterior is (-∞, ∞)). This is done using the <code>asflat</code> function.</p><pre><code class="language-julia hljs">tpost = asflat(post)
ndim = dimension(tpost)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1363</code></pre><p>Our Posterior and TransformedPosterior objects satisfy the <code>LogDensityProblems</code> interface. This allows us to easily switch between different AD backends and many of Julia&#39;s statistical inference packages use this interface as well.</p><pre><code class="language-julia hljs">using LogDensityProblemsAD
using Zygote
gtpost = ADgradient(Val(:Zygote), tpost)
x0 = randn(ndim)
LogDensityProblemsAD.logdensity_and_gradient(gtpost, x0)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(-1.856235656524847e7, [867815.9908553365, -26652.383510390144, -46872.1057626401, -73357.2895654218, -18250.508307674674, -38335.041283956205, -349003.15827689273, -84869.13507377537, -124274.65280652816, -358981.31352953677  …  -112421.73128048607, 137311.46537384734, 743.2243543751688, 6065.19986834864, -407.0199924446326, 654.2913885118811, 2118.174518184216, 1461.0223308506759, -3006.8799566057282, 2151.3041673563202])</code></pre><p>We can now also find the dimension of our posterior or the number of parameters we are going to sample. !!! Warning     This can often be different from what you would expect. This is especially true when using     angular variables where we often artificially increase the dimension     of the parameter space to make sampling easier.</p><p>To initialize our sampler we will use optimize using LBFGS</p><pre><code class="language-julia hljs">using ComradeOptimization
using OptimizationOptimJL
f = OptimizationFunction(tpost, Optimization.AutoZygote())
prob = Optimization.OptimizationProblem(f, 2*rand(rng, ndim) .- 1.0, nothing)
ℓ = logdensityof(tpost)
sol = solve(prob, LBFGS(), maxiters=5_000, g_tol=1e-1, callback=((x,p)-&gt;(@info f(x,p); false)))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">u: 1363-element Vector{Float64}:
   0.3095314955785601
 -11.429547043155148
  -2.3506066276056115
  -1.7526815081793148
  -1.6010725676248447
  -1.4899287246281292
  -1.429019406232864
  -1.3923803186323624
  -1.4309920954923805
  -1.7491082357209868
   ⋮
   0.8143246114056419
  -0.650326926760172
   0.6481716160307224
  -0.926892933976675
   0.18582339158667668
  -0.8432772814664882
   0.4352905817427628
   0.38115079158715776
   0.8628928812912552</code></pre><p>Now transform back to parameter space</p><pre><code class="language-julia hljs">xopt = transform(tpost, sol.u)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(fg = 0.5767709003998904, c = [1.0625151964129261e-8 1.0909655742664804e-6 … 4.031661808672145e-6 1.5598022484862373e-6; 9.325091713501462e-5 3.965379147652281e-5 … 6.560038826642137e-5 1.5153605673877819e-5; … ; 2.68397824898662e-10 9.255436784063251e-5 … 0.00014429883727563265 0.0007298341369857183; 4.0649135648218164e-7 1.788130717248107e-6 … 9.317922822331208e-6 0.0012745926241610967], lgamp = [0.0006799865116965375, -0.0002767825666330136, -0.5390536237732709, 0.1440571418261221, 0.04409326957698789, -0.04382097919001401, 0.02229971808350372, 0.22642735526266422, 0.033153045745557226, -0.03290124702554607  …  -0.030719376835079044, -0.0007279776682728243, -0.6970164065239713, -0.01118303398854923, -0.01225512456348719, 0.01231217565852815, 0.0036012451100864928, 0.00047280257270196, -0.7420233409731233, -0.014491363260096533], gphase = [-0.8137672700963592, -2.9815462143193203, -2.9485601479095127, -0.8704843016812744, -2.9215062928834223, -3.1108898148048993, -0.928190028327095, -2.8857175100827552, 3.004089535757697, -0.9766524853605897  …  -0.5846462946897726, -0.6977246108001508, -1.4111484994606298, -0.9034921135751489, 0.3607163470263783, -0.5239321090731802, -0.787058010273716, -1.3729393787934094, -1.0942814380126327, 0.41594091680359135])</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"></div></div><p>Fitting gains tends to be very difficult, meaning that optimization can take a lot longer.    The upside is that we usually get nicer images.</p><p>First we will evaluate our fit by plotting the residuals</p><pre><code class="language-julia hljs">using Plots
residual(model(xopt, metadata), dvis)</code></pre><p>These look reasonable, although there may be some minor overfitting. This could be improved in a few ways, but that is beyond the goal of this quick tutorial. Plotting the image, we see that we have a much cleaner version of the closure-only image from <a href="../imaging_closures/#Imaging-a-Black-Hole-using-only-Closure-Quantities">Imaging a Black Hole using only Closure Quantities</a>.</p><pre><code class="language-julia hljs">img = intensitymap(model(xopt, metadata), fovx, fovy, 128, 128)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-dimensional KeyedArray(NamedDimsArray(...)) with keys:
↓   X ∈ 128-element LinRange{Float64,...}
→   Y ∈ 128-element LinRange{Float64,...}
And data, 128×128 NamedDimsArray(::Matrix{Float64}, (:X, :Y)):
                 (-1.56333e-10)  …  (1.53872e-10)  (1.56333e-10)
 (-1.56333e-10)     4.73456e-7        4.53808e-7     4.39306e-7
 (-1.53872e-10)     5.83404e-7        4.93692e-7     4.65182e-7
 (-1.5141e-10)      7.76649e-7        5.56481e-7     5.05511e-7
 (-1.48948e-10)     1.05112e-6        6.4477e-7      5.61967e-7
 (-1.46486e-10)     1.37968e-6   …    7.58057e-7     6.34355e-7
 (-1.44024e-10)     1.7341e-6         8.95709e-7     7.22398e-7
    ⋮                            ⋱    ⋮            
  (1.41562e-10)     5.5077e-7         1.74668e-5     1.46549e-5
  (1.44024e-10)     5.15902e-7        1.78278e-5     1.49889e-5
  (1.46486e-10)     4.85859e-7   …    1.88205e-5     1.58672e-5
  (1.48948e-10)     4.60999e-7        1.96704e-5     1.66276e-5
  (1.5141e-10)      4.41557e-7        1.95817e-5     1.65897e-5
  (1.53872e-10)     4.27731e-7        1.77947e-5     1.51039e-5
  (1.56333e-10)     4.18986e-7        1.4367e-5      1.22174e-5</code></pre><p>plot(img, title=&quot;MAP Image&quot;)</p><p>Because we also fit the instrument model, we can inspect their parameters. To do this, <code>Comrade</code> provides a <code>caltable</code> function that converts the flattened gain parameters to a tabular format based on the time and its segmentation.</p><pre><code class="language-julia hljs">gt = Comrade.caltable(gcachep, xopt.gphase)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">───────┬─────────────────────────────────────────────────────
  time │      AP       AZ       JC      LM       PV       SM
───────┼─────────────────────────────────────────────────────
 0.917 │  -0.814  missing  missing  -2.982   -2.949  missing
 1.217 │   -0.87  missing  missing  -2.922   -3.111  missing
 1.517 │  -0.928  missing  missing  -2.886    3.004  missing
 1.817 │  -0.977  missing  missing  -2.862    2.842  missing
 2.117 │  -1.002  missing  missing  -2.822    2.671  missing
  2.45 │  -0.303  missing  missing   2.427   -3.124  missing
  2.75 │  -1.045  missing  missing  -2.811     2.24  missing
  3.05 │  -1.132  missing  missing  -2.804    2.015  missing
  3.35 │  -1.152  missing  missing  -2.837     1.78  missing
 3.683 │  -1.163    2.554  missing  -2.925    1.505  missing
 3.983 │  -1.167    2.356  missing  -3.001    1.239  missing
 4.283 │  -1.159    2.144  missing  -3.098    0.995  missing
 4.583 │  -1.143    1.909   -2.023   3.067    0.709  missing
 4.917 │  -1.074    1.657   -1.892   2.892    0.405    1.751
 5.183 │  -1.078    1.459    -1.82   2.706    0.164    1.526
  5.45 │  -1.119    1.295   -1.754   2.471   -0.062    1.298
   ⋮   │    ⋮        ⋮        ⋮       ⋮        ⋮        ⋮
───────┴─────────────────────────────────────────────────────
                                               9 rows omitted
</code></pre><p>plot(gt, layout=(3,3), size=(600,500)) The gain phases are pretty random, although much of this is due to us picking a random reference station for each scan.</p><p>Moving onto the gain amplitudes, we see that most of the gain variation is within 10% as expected except LMT, which has massive variations.</p><pre><code class="language-julia hljs">gt = Comrade.caltable(gcache, exp.(xopt.lgamp))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">───────┬─────────────────────────────────────────────────────────────
  time │      AA       AP       AZ       JC     LM       PV       SM
───────┼─────────────────────────────────────────────────────────────
 0.917 │   1.001      1.0  missing  missing  0.583    1.155  missing
 1.217 │   1.045    0.957  missing  missing  1.023    1.254  missing
 1.517 │   1.034    0.968  missing  missing  1.226    1.178  missing
 1.817 │   1.024    0.977  missing  missing  1.187    1.184  missing
 2.117 │   1.025    0.976  missing  missing  1.159    1.091  missing
  2.45 │ missing    0.906  missing  missing  0.954    0.957  missing
  2.75 │   1.021     0.98  missing  missing  0.718    1.087  missing
  3.05 │   0.992    1.008  missing  missing  0.637    1.081  missing
  3.35 │   0.981    1.019  missing  missing  0.582    1.098  missing
 3.683 │   1.042     0.96    0.969  missing  0.515    1.077  missing
 3.983 │   0.984    1.016    1.036  missing   0.55    1.135  missing
 4.283 │    0.98     1.02    0.986  missing   0.62    1.156  missing
 4.583 │    0.99     1.01    0.982    1.023  0.527    1.228  missing
 4.917 │    0.96    1.042    0.971    1.001  0.502    1.263    1.004
 5.183 │   0.953    1.049    0.963      1.0  0.478    1.496    0.992
  5.45 │   0.846     1.18    0.952    0.995  0.482    1.093    0.994
   ⋮   │    ⋮        ⋮        ⋮        ⋮       ⋮       ⋮        ⋮
───────┴─────────────────────────────────────────────────────────────
                                                       9 rows omitted
</code></pre><p>plot(gt, layout=(3,3), size=(600,500))</p><p>To sample from the posterior, we will use HMC, specifically the NUTS algorithm. For information about NUTS, see Michael Betancourt&#39;s <a href="https://arxiv.org/abs/1701.02434">notes</a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For our <code>metric,</code> we use a diagonal matrix due to easier tuning</p></div></div><p>However, due to the need to sample a large number of gain parameters, constructing the posterior is rather time-consuming. Therefore, for this tutorial, we will only do a quick preliminary run, and any posterior inferences should be appropriately skeptical.</p><pre><code class="language- hljs">using ComradeAHMC
metric = DenseEuclideanMetric(ndim)
chain, stats = sample(rng, post, AHMC(;metric, autodiff=Val(:Zygote)), 500; nadapts=200, init_params=chain[end])</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This should be run for likely an order of magnitude more steps to properly estimate expectations of the posterior</p></div></div><p>Now that we have our posterior, we can put error bars on all of our plots above. Let&#39;s start by finding the mean and standard deviation of the gain phases</p><pre><code class="language- hljs">gphase  = hcat(chain.gphase...)
mgphase = mean(gphase, dims=2)
sgphase = std(gphase, dims=2)</code></pre><p>and now the gain amplitudes</p><pre><code class="language- hljs">gamp  = exp.(hcat(chain.lgamp...))
mgamp = mean(gamp, dims=2)
sgamp = std(gamp, dims=2)</code></pre><p>Now we can use the measurements package to automatically plot everything with error bars. First we create a <code>caltable</code> the same way but making sure all of our variables have errors attached to them.</p><pre><code class="language- hljs">using Measurements
gmeas_am = measurement.(mgamp, sgamp)
ctable_am = caltable(gcache, vec(gmeas_am)) # caltable expects gmeas_am to be a Vector
gmeas_ph = measurement.(mgphase, sgphase)
ctable_ph = caltable(gcachep, vec(gmeas_ph))</code></pre><p>Now let&#39;s plot the phase curves plot(ctable_ph, layout=(3,3), size=(600,500))</p><p>and now the amplitude curves plot(ctable_am, layout=(3,3), size=(600,500))</p><p>Finally let&#39;s construct some representative image reconstructions.</p><pre><code class="language- hljs">samples = model.(chain[201:10:end], Ref(metadata))
imgs = intensitymap.(samples, μas2rad(75.0), μas2rad(75.0), 128,  128);

mimg = mean(imgs)
simg = std(imgs)</code></pre><p>p1 = plot(mimg, title=&quot;Mean&quot;, clims=(0.0, maximum(mimg))); p2 = plot(simg,  title=&quot;Std. Dev.&quot;, clims=(0.0, maximum(mimg))); p3 = plot(imgs[begin],  title=&quot;Draw 1&quot;, clims = (0.0, maximum(mimg))); p4 = plot(imgs[end],  title=&quot;Draw 2&quot;, clims = (0.0, maximum(mimg))); plot(p1,p2,p3,p4, layout=(2,2), size=(800,800))</p><p>And viola, you have just finished making a preliminary image and instrument model reconstruction. In reality, you should run the <code>sample</code> step for many more MCMC steps to get a reliable estimate for the reconstructed image and instrument model parameters.</p><p>Computing information</p><pre><code class="nohighlight hljs">Julia Version 1.7.3
Commit 742b9abb4d (2022-05-06 12:58 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: 11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-12.0.1 (ORCJIT, tigerlake)</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 16 April 2023 20:44">Sunday 16 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
